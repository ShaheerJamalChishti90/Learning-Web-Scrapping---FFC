{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3db6f0ad",
   "metadata": {},
   "source": [
    "# Scrapping TimesJobs Website "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9834f026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "507a1e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://m.timesjobs.com/mobile/jobs-search-result.html?txtKeywords=Python&cboWorkExp1=-1&txtLocation=\"\n",
    "web = requests.get(url).content\n",
    "soup = BeautifulSoup(web, \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f52c3f1",
   "metadata": {},
   "source": [
    "yahan mein parent-child relation use karounga through out the code kyun ke \"li\" ke paas apni class nahi hai jiski wajha se mujhe \"li\" ke parent(ul) ko access karna par raha hai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2877e3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This allows me to get \"ul\" which is the parent of \"li\", after accessing the \"ul\" with the help of its id, i was fetched \"li\" bc i already got \"ul\" \n",
    "#I did all of this bc \"li\" didnt has its own id, so i had to access it through its parent \"ul\"\n",
    "\n",
    "jobs_html = soup.find(\"ul\", {\"id\": \"jobsListULid\"}).find(\"li\")\n",
    "print(jobs_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ce059b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Engineer\n"
     ]
    }
   ],
   "source": [
    "#Doing the same thing here, this time just reading the data from the \"jobs_html\", finding its div and accessing it through its class after getting the \"div\" im fiding \"h3\" tag inside it and fetching its text \n",
    "# I did all of this because the \"h3\" tag is not unique, so i had to access it through its parent \"div\" and then get the text from it\n",
    "\n",
    "job_position = jobs_html.find(\"div\", {\"class\": \"srp-job-heading\"}).find(\"h3\").text.strip()\n",
    "print(job_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d18fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I did try to access the \"h3\" tag directly from the \"jobs_html\" but it returned None, so i had to access it through its parent \"div\" and then get the text from it\n",
    "\n",
    "job_position = jobs_html.find(\"h3\", class_ = \"ui-link\")\n",
    "# print(job_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c782f0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "east india securities ltd.\n",
      "Date Posted | 1 days ago\n"
     ]
    }
   ],
   "source": [
    "company_name = jobs_html.find(\"div\", {\"class\": \"srp-job-heading\"}).find(\"h4\").text.strip()\n",
    "print(str(company_name)[:-13])\n",
    "print(f\"Date Posted{str(company_name)[-13:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "74a069aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"srphglt\" href=\"https://m.timesjobs.com/jobskill/python-jobs\" title=\"python Jobs\">python</a>, <a class=\"srphglt\" href=\"https://m.timesjobs.com/jobskill/hadoop-jobs\" title=\"hadoop Jobs\">hadoop</a>, <a class=\"srphglt\" href=\"https://m.timesjobs.com/jobskill/machine-learning-jobs\" title=\"machine learning Jobs\">machine learning</a>]\n"
     ]
    }
   ],
   "source": [
    "skills_tags = jobs_html.find(\"div\", {\"class\": \"srp-keyskills\"}).find_all(\"a\")\n",
    "# skills_tags = jobs_html.find(\"div\", {\"class\": \"srp-keyskills\"}).find(\"a\").text.strip()\n",
    "print(skills_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c1aa94dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python, hadoop, machine learning, "
     ]
    }
   ],
   "source": [
    "for skill in skills_tags:\n",
    "    print(skill.text.strip(), end=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b1506562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolkata\n",
      "2 - 5  Years\n",
      "As per Industry Standards\n"
     ]
    }
   ],
   "source": [
    "# loc_exp_sal = jobs_html.find(\"div\", {\"class\":\"clearfix exp-loc\"}).find_all(\"div\")\n",
    "loc_exp_sal = jobs_html.find(\"div\", class_ = \"clearfix exp-loc\").find_all(\"div\")\n",
    "# print(loc_exp_sal)\n",
    "\n",
    "for item in loc_exp_sal:\n",
    "    print(item.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fca6878",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
